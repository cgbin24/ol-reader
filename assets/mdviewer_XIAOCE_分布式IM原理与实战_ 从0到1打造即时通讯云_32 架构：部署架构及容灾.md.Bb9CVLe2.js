import{_ as t}from"./app.BdTF1atn.js";import{j as p,i as o,Z as i}from"./chunks/@vue.D6nrJjhM.js";/* empty css                          */import"./chunks/@vueuse.ErXst1iV.js";const k=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"mdviewer/XIAOCE/分布式IM原理与实战: 从0到1打造即时通讯云/32 架构：部署架构及容灾.md","filePath":"mdviewer/XIAOCE/分布式IM原理与实战: 从0到1打造即时通讯云/32 架构：部署架构及容灾.md"}'),s={name:"mdviewer/XIAOCE/分布式IM原理与实战: 从0到1打造即时通讯云/32 架构：部署架构及容灾.md"},r=i('<p>经历了四个里程碑的迭代，系统终于要上线了！上线不是一个终点，而是另一个起点；</p><blockquote><p><strong>它就像即将毕业的学子，终将面临社会的考验</strong>。</p></blockquote><p>一旦上线，它就将成为一辆永不停止的列车，你要不停升级硬件设施从而提高乘客的舒适度，同时也要避免故障发生的次数和减少影响时间；而当列车中的乘客越来越多时，你还要考虑如何给<strong>飞速行驶的列车更换引擎</strong>。所幸，我们已经从<code>基准测试</code>、<code>系统优化</code>、<code>灰度发布</code>、<code>智能路由</code>和<code>日志监控</code>这5方面做了相对充分的准备。本章节将从如下两方面展开：</p><ol><li>部署逻辑及架构设计。</li><li>容灾设计及考虑。</li></ol><h3 id="部署计划" tabindex="-1">部署计划 ​</h3><p>如今的系统都非常复杂，涉及到大量的服务，它们之间的调用关系都会非常复杂，这也就导致系统设计者需要配合运维人员来部署。它会涉及到如下几方面：</p><ol><li><strong>硬件资源</strong>：通过对核心服务的基准测试，可以根据业务量估算出所需的硬件资源。如果是部署在k8s环境，并且服务可以很灵活的扩容，可以不用在初始状态时考虑资源过多的冗余；但是如果基础环境较差的情况下，是需要运维介入手动扩容，则要考虑多冗余点资源。</li><li><strong>容灾设计</strong>：除了服务不能有单节点之外，有状态的数据节点也要考虑高可用部署方案。</li><li><strong>部署架构</strong>：包括服务之间的调用关系，所在机房IDC，网络等。</li></ol><h4 id="单机房部署" tabindex="-1">单机房部署 ​</h4><p>在一个单机房的部署模式中，所有服务会在同一个子网中，或者是一个云服务的VPC（virtual private cloud）网络中，调用关系最简单。如下是一个最小单位的部署架构图：</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/22b8dc1df51a497684d573fd73a65b0b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="kim_deploay_idc.png"></p><p>虽然是最小单位，但是zone至少要有两个，否则灰度发布逻辑也就无法实施。资源如下：</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc1ce6d63c8d483c87b9c759029614b6~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="kim_deploay_idc_host.png"></p><p>以上一共是6台服务器，在部署时单台服务器往往可以运行多个服务实例，最大化利用cpu等资源。在上图中，网关与路由服务是需要对外暴露的，因此可以把网关等服务部署在具有双网卡的服务器上，也就是会有一个公网网卡，配有一个公网IP。如果服务器没有公网IP，就只能通过具有公网IP的反向代理做流量转发了。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/400c89d6a3184bedbae5a4f67183c778~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="kim_deploay_idc_host_SLB.png"></p><p>其中SLB又分为<strong>四层负载</strong>或<strong>七层负载</strong>，也就是tcp层的流量转发或应用层的流量转发，比如nginx就是七层负载，可以作为<strong>网关服务</strong>websocke协议t和<strong>路由服务</strong>http协议的SLB层，只不过如此一来router的路由功能就会被弱化。到目前为止，核心服务不会有单点故障问题，但是数据库与缓存都是单节点部署，如果节点宕机，就会导致服务不可用，而且数据也可能丢失。因此，从容灾的角度考虑，需要考虑MySQL及Redis的高可用方案。</p><p>这其中，Redis的<strong>哨兵模式</strong>就是一个相对完善的高可用方案，它解决了如下三个主要问题：</p><ol><li>通过<strong>主从复制</strong>，解决单节故障问题，虽然<strong>主从异步复制</strong>可能会导致部分数据丢失，但是作为一个以缓存为主要业务场景的模式下，是可以接收的。</li><li>通过<strong>哨兵集群</strong>，解决master节点故障时，从多个slave中选举一个成为新的master节点，提供<strong>读写</strong>服务，否则即使SDK重连到从节点，它也是不提供写服务的。</li><li>通过<strong>SDK逻辑</strong>，解决了SDK自动切换新master节点问题。</li></ol><p>当主节点故障时，不需要人工处理，系统就能自动恢复。而MySQL要相对复杂很多，因此我们主要来看下它的高可用方案。</p><h4 id="mysql高可用" tabindex="-1">MySQL高可用 ​</h4><p>任何大量被应用在生产环境的数据库不可能没有高可用方案，MySQL也不可能例外，它内建的复制功能是构建基于MySQL的大规模、高性能、高可用性应用的基础。当然在本章不会详细介绍它的原理，我们只需要对它有个大致的了解，以帮助我们选择一个合理的高可用方案。</p><p>MySQL支持两种复制方式：基于<strong>行的复制</strong>和基于<strong>语句的复制</strong>。基于语句的复制可以理解为复制对数据造成更改的语句，当从库重放这些语句时，实际上只是把主库上执行过的SQL再执行一遍。这种方式的好处就是逻辑非常简单，但是坏处就是由于是重放的是SQL，会导致一些SQL执行的结果与主库中不同，比如SQL中有读取当前时间写入一个字段。基于行的复制就是直接复制数据，它的优化就是可以正确的复制每一行，不过缺点也很明显。比如执行一条Update语句对1000行产生了影响，如果是基于语句的复制，只需要复制一行即可，但是基于行的复制就要把这1000行的数据全复制过去。至于选择何种复制方式在这里就不深入了，读者可以自行选择。</p><p>接下来，我们来看看MySQL的复制拓扑。以如下两种来说明：</p><ol><li><strong>一主库多备库</strong></li></ol><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/68af65c6bf8440e69b8439214a7872bb~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="mysql_master_mult_slave.png"></p><blockquote><p>如果在备库中执行更新类语言会被拒决。</p></blockquote><p>这是一种最简单的拓扑结构，但它非常灵活，能满足多种需求。比如：</p><ul><li>把一台备库用作灾难恢复。</li><li>其中一台备库放到另一个数据中心，用于跨机房的数据容灾。</li><li>将一台备库给其它角色使用，比如开发可以在备库查询数据分析问题，而不是在主库查询数据时慢SQL导致事故。</li></ul><ol start="2"><li><strong>主-主复制</strong></li></ol><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8dacb1fc20424d2babf6a1a9ad988ff8~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="mysql_master_master.png"></p><p>主-主复制模式下，每个主库都是对方的备库，但是在使用过程中要注意数据冲突，比如自增主键表就会导致数据同步失败，虽然MySQL提供了auto_increment_increment与auto_increment_offset两个自增属性，但是要谨慎使用。同时主-主复制模式下，也会有两种使用场景，我们在后面再介绍。</p><p>虽然MySQL的复制拓扑非常灵活，不过记住下面的基本原则即可：</p><ul><li>一个MySQL备库实例只能有一个主库。</li><li>一个主库可以有多个备库。</li><li>一个备库可以把主库复制过来的数据传播给其它备库。</li></ul><p>说完了同步拓扑结构，在实际应用中还要结合场景使用，还要考虑同步模式，MySQL有三种同步方式：</p><ol><li>异步复制。</li><li>半同步复制。</li><li>同步复制。</li></ol><p><strong>异步复制</strong>对事务的性能影响最小，但是主库如果宕机，就会导致数据丢失。而<strong>半同步复制</strong>可以保证数据至少同步给了一台备库，但是不能保证事务在备库重放完成，要保证这一点就需要使用<strong>同步复制</strong>模式，不过同步复制模式下，数据库的吞吐量也是最低的。</p><p>了解了以上内容，接下来只需要解决主库故障时，服务中切换数据库的问题，这里就可以通过vip技术以较小的代价实现。逻辑如下：</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f62f1ae9081c416c8edd8e044226de35~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="mysql_master_vip_1.png"></p><p>在服务royal中配置数据库连接时，配置的是一个vip，当主库故障时，vip会自动切换另一台主机上，此时程序端在自动重连机制下就会重新与新的数据库建立连接。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a43bcbebc19a4b8da39673b6e25fcd55~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="mysql_master_vip_2.png"></p><h4 id="多区域部署" tabindex="-1">多区域部署 ​</h4><p>当业务范围涉及到海外，或者有一些用户的地理位置离中心机房的位置较远，数据包经过公网到达中心机房的延迟会较高，或者丢包率增加时，这一地区的用户体验就会直线下降，导致这是问题的原因主要有两点：</p><ul><li>信号在网络中传输的时间会变大。</li><li>经过的跳跃点增加，受到的影响因素加大。</li></ul><p>在这种情况下，我们就可以在该地区就近的数据中心部署网关节点，此IDC与核心服务所在的数据中心通过高速光纤连接，它可以在很大程序上保证网络质量的稳定可靠性，此时一个相对简单的部署逻辑就变成如下样子。</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/88885028bf764e12a51f0fabb0593558~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="kim_deploay_idc_multi.png"></p><p>在前面章节中，我们介绍过了router的作用，在示例中根据地理位置路由的最小粒度是国家，但是只要稍作修改就可以把控制粒度缩小到城市。SDK通过router服务就可以连接到就近的网关，比如在香港的用户可以连接到<strong>IDC_ALI_HK</strong>这个IDC的网关上去，而在上海的另一个用户就会被路由到<strong>IDC_ALI_SH</strong>这个数据中心的网关上。虽然网关所在的地理位置不同，但是chat、royal等服务都是在<strong>IDC_ALI_SH</strong>。</p><h4 id="同城双活部署" tabindex="-1">同城双活部署 ​</h4><p>在介绍同城双活之前，我们需要知道，同城双活的目的是为了解决<strong>机房级故障时服务的可用性</strong>。即使是国内排名第一的阿里云也曾出现过几次大规模宕机，只要出现这种情况，基本上你的系统SLA就不可能达到99.99%，也就是故障时间不超过52分钟。但是做双活的代价是巨大的，特别是从不支持到支持双活，架构及逻辑的重构成本是非常高的。这里的原因主要有如下几点：</p><ol><li>由于微服务众多，可能会有一些边缘服务是有状态的。</li><li>核心中间件如MQ、配置中心要考虑双机房部署，并且要考虑数据一致性问题。</li><li>数据库虽然可以通过双主实现双写，但是业务层服务可能采用自增主健，双写会导致数据冲突。另一方面，流量没有根据逻辑做路由，在一个IDC写入的数据，可能在另一个IDC中要立刻读取，以前面介绍的Mysql同步原理为例，就需要采用<strong>全同步复制方案</strong>，这种情况下除了写IO会降低，对两个IDC之间的宽带、延迟和稳定性要求极高。当然，也可以采用伪数据库方案，也就是双机房的服务默认情况下还是只读写一个IDC的数据库，另一个机房的数据库作为备库。</li><li>缓存一致性问题。</li></ol><p>接下来，我们看看在KIM中是如何实现的。一个大致的部署架构图如下：</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fdd1fa5b79ae4367a418483a83d0215c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="kim_deploay_two_idc_alive.png"></p><p>这里需要注意如下几点：</p><ul><li><strong>其一</strong>，可以看到两个机房是IDC_ALI_SH与IDC_HW_SH，它们是在两个不同云服务商，同一城市的两个不同物理位置的机房。这里有几个信息需要注意到： 云服务商不同，保证不会因为服务商故障导致两个机房都不可用。 同一城市，要保证两个机房的绝对距离不能超过一定距离，比如100KM，这样ping包的延迟在5ms以内。 机房所在位置不同，虽然是不同的云服务商，但是它们提供的机房可能是在同一个物理位置，因此要避免这种情况。</li><li><strong>其二</strong>，由于我们在网关层可以根据App来做流量分区，这样可以保证两个机房的数据不会存在交集，比如App1的数据落在<strong>zone_1</strong>，而App2的数据落在<strong>zone_2</strong>，这样数据库的双写双读就不要求数据的<strong>强一致</strong>，可以采用半同步方式。</li><li><strong>其三</strong>，consul可以部署在两个不同的机房，因为它本身就是分布式服务。</li><li><strong>其四</strong>，redis由于存储了会话信息，因此如果修改网关中的路由配置，导致App分区变动，就要把此App中登录用户踢下线，使其重新登录到新的分区，生成会话。</li></ul><h3 id="最后总结" tabindex="-1">最后总结 ​</h3><p>本章从单机房部署架构到多机房部署，介绍了高可用及容灾方面的知识点，虽然容灾是一个很大的话题，但是并不影响我们从局部来谈论kim系统的高可用性。就像同城双活虽然可以提高系统可用性，但是它的代价是巨大的。虽然不一定用的到，但是我希望读者可以通过自己的思考，有所收获。</p><p>最后，经过32个章节，6个月的里程，本小册也告以段落。</p>',55),e=[r];function l(n,c,a,g,_,m){return o(),p("div",null,e)}const j=t(s,[["render",l]]);export{k as __pageData,j as default};
