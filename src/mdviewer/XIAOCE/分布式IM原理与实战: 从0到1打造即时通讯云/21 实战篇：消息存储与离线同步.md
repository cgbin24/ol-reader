在上一章节，我们了解了消息可靠投递的基本原理，那么本章的任务就是实战演练~

![chapter21.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/42cabd0dfad5428595cf170b4b3b154c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

### 存储设计

在即时通讯IM这个业务场景中，有`单聊`与`群聊`两个最基本的场景。在前面我们介绍过，消息的可靠性要求服务端`存储`一段时间内的消息。因此这里就会涉及到`如何存储消息的问题`。

#### 同步vs异步

> 为什么会提出上面这个看似简单的问题呢？

在思考这个问题之前，我们首先要搞明白几个关键点：

1. 因为我们最终要把消息落在数据库中，而数据库表相对于`Write-Ahead Log`（WAL预写日志）之类的文件队列或者NOSQL数据库，写性能上的瓶颈还是很明显的。
2. 消息是`同步`存储，还是`异步`存储？

    - `同步`：消息写入数据库，确认**事务提交**完成再返回。
    - `异步`：消息写入一个高速缓存，或者消息中间件就可以返回。然后由**其它线程**把暂存的消息慢慢写入数据库中。

3. 同步存储情况下，存储消息的`写性能瓶颈`会直接影响`消息转发吞吐量`，如何优化？
4. 异步存储情况下，群聊的**消息转发吞吐量**的压力会落到`寻址`这个逻辑上，但是如何`保证消息的可靠性`？

首先，**同步或异步存储不是重点**，`重点`是`保证消息可靠投递`的同时如何尽量提高`消息转发吞吐量`。如果是同步存储情况下，消息投递的可靠性在前一章节我们设计的逻辑下是没有问题的，当然不是说100%可靠，这就像系统SLA(可用性)不可能达到100%一样。因此我们需要根据业务量来评估一个`可靠且相对简单`的方案，毕竟在功能与成本之间的平稳考量无处不在。

> 那么我们看下异步情况下，要如何才能保证离线消息不丢失？

**首先我们来看一种可能的情况**：用户A给依次间隔一点时间给用户B发送了5条消息，用户B在收到`2条消息`之后离线了，但是在很短的时间内（5条消息已经发送完成之后），又重连登录到服务器，由于消息的异步存储逻辑，假设此时那`3条消息`还**未存储**。因此如果用户B通过本地存储的`第2条消息的ID`去请求同步离线消息，则会返回了`0条离线消息`；如果用户B没有本地存储，那么同步离线消息则只会同步`前面2条已经存储完成但是未被ACK跳过的消息`。此时如果用户B收到一条**在线的消息**，由于ACK机制，会把读索引重置到新的消息位置上，从而导致`前面的3条消息丢失`，即使下次登录也不会再同步它们。

因此，异步情况下，如果要保证消息不会丢失，可以采用的一个大致的逻辑就是`双读`。如下图所示

![two_level_read.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/09a0092ae8f44e9b844673db06c9d28b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

当然，实际的逻辑肯定不是这么简单，这也不是一个唯一的方案。在本小册的实战项目中我们采用`同步存储`的方案，这是一个较为折中的方案，逻辑相对简单，而且消息的存储性能也是有一些提升空间的。

> 确定了主要逻辑，接下来就是消息表存储结构的设计了！

#### 扩散写

在单聊中我们只需把消息投递给一人即可，因此只需要给每个用户分配一个**离线消息队列**，把消息写进去即可。如下图：

![user_msg_queue.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e37c750f9cbd4975a9e7bdb46fbfee20~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

如上所示，`离线队列`是以用户为单位，因此每个用户的离线队列中包括了`任何人发送过来的消息`，每个队列之间没有关系。同样的道理，在群聊中，消息要扩散投递给群中所有的成员，因此也可以把消息写到每个成员的群消息队列中。如下图：

![user_group_msg_queue.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3032d226787f4003a27c25b32b4878d7~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

在上图的示例中，用户B给群`G1`发送了两条消息，它们被扩散写到了群中的其它用户的离线队列中。读者需要注意的是，以上两张逻辑示意图中，**发送方的消息没有存储在自己的离线队列**，这一点我们在后面再说明。

以上单聊与群聊的存储逻辑就是`写扩散`了。它的优点就是离线消息的`读非常简单`，而且写的逻辑也不复杂。但是在群的扩散中，主要有两个缺点：

1. 因为消息被扩散存储了`多份`，因此更加占用硬盘空间。
2. 同时，同步逻辑下消息存储的性能会下降，主要影响群消息的**转发吞吐量**。

#### 读扩散

读扩散的另一层意思就是消息**不会写多份**，实际上在上一章节中`消息索引`的存储结构就是一个`读扩散`的结构。如下图所示：

![user_msg_queue_2.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/70f601c7fb46408eacb2ff9414efc786~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

可以看到，与上面的逻辑不同的是，**每个发送者与接收者之间会有一个独立的队列**，用户A读取消息时必须从多个队列中同时读取。之所以说它的实际意义不是非常大，是因为如果我们使用数据库存储的话，它的结构可以是这样的：

|id|	receiver|	sender|	type|	body|
| - | - | - | - | - |
|11111|	`user_a`|	user_b|	text|	msg1|
|11112|	`user_a`|	user_b|	text|	msg2|
|11113|	`user_a`|	user_b|	text|	msg3|
|11115|	`user_a`|	user_c|	text|	msg4|
|11116|	`user_a`|	user_c|	text|	msg5|
|11117|	`user_a`|	user_d|	text|	msg6|
|11118|	user_b|	`user_a`|	text|	msg7|

**那么读取user_a的`离线消息`就是：**

> select id,type,body from t_message where `receiver='user_a'` and `id>11111`;

因为消息都在一张表中，实际上**没有读扩散一说**。当然，假设把消息存储了物理隔离的队列中，那么读取一个用户的所有单聊离线消息，首先就要查询出`好友列表`，然后再遍历`好友列表`依次取出队列中的消息。

不过，即时是使用数据库表，如果我们要读取user_a的`历史消息`，那么查询语句就要`包括自己发送的消息`，比如QQ就有历史消息漫游这个收费功能，在微信上是没有的。那么查询语句就变为如下所示：

> select id,type,body from t_message where (`receiver='user_a' or sender='user_a'`) and `id>11111`;

可以看到在这种情况下，才发生了读扩散，而且这个SQL优化空间有限，很难支持千万级别的毫秒查询。实际上，**在支持多设备登录的情况下，比如Phone端发送的消息对同一个用户的PC端来说，也是离线消息，也需要同步**。

> 以上SQL示例中需要说明的是 `id>11111` 只是为了说明一个逻辑，即`查询时取的离线消息是在消息11111之后`。

同样，群的`读扩散`模式下的存储逻辑如下。

![group_msg_queue_2.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f2976529d45d4fc5a2e80692de83b380~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

相信读者应该看出来了，它的特点就是`消息只需要写一份`，但是读取时则要`从多个群中读取`。我们用下面这张表来说明：

|id|	`group_id`|	sender|	type|	body|
| - | - | - | - | - |
|11111|	1|	user_b|	text|	msg1|
|11112|	1|	user_b|	text|	msg2|
|11113|	1|	user_b|	text|	msg3|
|11115|	2|	user_c|	text|	msg4|
|11116|	2|	user_c|	text|	msg5|
|11117|	3|	user_d|	text|	msg6|

因此用户读取群的离线消息时，首先就要`查询出用户所有的群`，然后再查询消息。

- `第1步`: 查询出用户所有的群

> select id from t_group_member where `member='user_a'` <-- 从成员表查询出所有的群ID，返回1,2,3

- `第2步`: 查询消息

> select id,type,body from t_group_message where `group in (1,2,3)` and id>11111;

#### 表结构设计

回到本章的主题。在本小册KIM实战项目中，我们使用`写扩散`的方案，主要是考虑逻辑更简单好理解。**同时结合上面给出的写扩散逻辑和上一章节的知识点**，最终得到我们的消息存储表结构：

> 索引表 t_message_index

```sql
+------------+------------------+------+-----+---------+----------------+
| Field      | Type             | Null | Key | Default | Extra          |
+------------+------------------+------+-----+---------+----------------+
| id         | bigint           | NO   | PRI | <null>  | auto_increment |
| account_a  | varchar(60)      | NO   | MUL | <null>  |                |
| account_b  | varchar(60)      | NO   |     | <null>  |                |
| direction  | tinyint unsigned | NO   |     | 0       |                |
| message_id | bigint           | NO   |     | <null>  |                |
| group      | varchar(30)      | YES  |     | <null>  |                |
| send_time  | bigint           | NO   | MUL | <null>  |                |
+------------+------------------+------+-----+---------+----------------+
```

**字段说明：**

- `id`：主键，在程序中会使用**分布式全局主键**写入。
- `account_a`：表示`队列拥有者`，即用户。
- `account_b`：表示另一方。
- `direction`：表示方向，`等于1`时表示account_a为消息发送方。
- `message_id`：表示消息内容ID，即t_message_content表中的id。
- `group`：表示群ID。
- `send_time`：表示消息发送时间。

在这里我们先简单给表中account_a和send_time添加两个BTREE`索引`。

> 内容表 t_message_content

```sql
+-----------+------------------+------+-----+---------+----------------+
| Field     | Type             | Null | Key | Default | Extra          |
+-----------+------------------+------+-----+---------+----------------+
| id        | bigint           | NO   | PRI | <null>  | auto_increment |
| type      | tinyint unsigned | YES  |     | 0       |                |
| body      | varchar(5000)    | NO   |     | <null>  |                |
| extra     | varchar(500)     | YES  |     | <null>  |                |
| send_time | bigint           | YES  | MUL | <null>  |                |
+-----------+------------------+------+-----+---------+----------------+
```

**字段说明：**

- `id`：消息主键，在程序中会使用**分布式全局主键**写入。
- `type`：消息类型。
- `body`：消息内容。
- `extra`：消息额外信息。
- `send_time`：表示消息发送时间。

> `示例1`：test1发送一条消息给test2

- `t_message_index`：扩散写

```sql
+---------------------+-------------+-------------+-----------+---------------------+-------+---------------------+
| id                  | account_a   | account_b   | direction | message_id          | group | send_time           |
+---------------------+-------------+-------------+-----------+---------------------+-------+---------------------+
| 1423159204287070209 | test2       | test1       | 0         | 1423159204287070208 |       | 1628142626866517000 |
| 1423159204287070210 | test1       | test2       | 1         | 1423159204287070208 |       | 1628142626866517000 |
+---------------------+-------------+-------------+-----------+---------------------+-------+---------------------+
```

- `t_message_content`：不区分单聊与群聊，永远是一条消息一条记录。

```sql
+---------------------+------+-------------+-------+---------------------+
| id                  | type | body        | extra | send_time           |
+---------------------+------+-------------+-------+---------------------+
| 1423159204287070208 | 1    | hello world |       | 1628142626866517000 |
+---------------------+------+-------------+-------+---------------------+
```

> `示例2`：test1发送一条消息给G1，`G1`成员有**test1**、**test2**、**test3**。

那么`t_message_index`表中的内容如下：

```sql
+---------------------+-----------+-----------+-----------+---------------------+---------------+---------------------+
| id                  | account_a | account_b | direction | message_id          | group         | send_time           |
+---------------------+-----------+-----------+-----------+---------------------+---------------+---------------------+
| 1423576900375928832 | test1     | test1     | 1         | 1423576900333985792 | b8ocxwzzizayy | 1628242156468452000 |
| 1423576900375928833 | test2     | test1     | 0         | 1423576900333985792 | b8ocxwzzizayy | 1628242156468452000 |
| 1423576900375928834 | test3     | test1     | 0         | 1423576900333985792 | b8ocxwzzizayy | 1628242156468452000 |
+---------------------+-----------+-----------+-----------+---------------------+---------------+---------------------+
```

因此，`无论是单聊还是群聊`，只需要通过如下SQL就可以查出某个用户的全部离线消息：

> SELECT `send_time,account_b,direction,message_id,group FROM t_message_index` WHERE account_a='test1' and send_time>1625650156541890000 ORDER BY send_time asc LIMIT 3000

> 通过direction标识，我们把消息分别往`接收方`与`发送方`的队列中写了一份。这样保证了每个用户都可以拿到自己的`全量消息`。无论是支持`历史消息查询`或者`多设备登录`等功能都是非常方便的。

### 消息存储实现

在`单聊与群聊`的通信层实现中，消息存储是通过调用royal这个RPC服务完成的。因此，在本章我们主要介绍下royal服务中具体的实现细节。其中**消息存储**与**在线消息ACK**就在如下几个接口中：
```go
messageAPI := app.Party("/api/:app/message")
{
        messageAPI.Post("/user", serviceHandler.InsertUserMessage)
        messageAPI.Post("/group", serviceHandler.InsertGroupMessage)
        messageAPI.Post("/ack", serviceHandler.MessageAck)
}
```

#### 单聊消息存储

逻辑就不介绍了哈，这里会使用到`h.Idgen.Next()`，也就是雪花算法生成的`分布式ID`。
```go
// services/service/handler/message_handler.go

package handler

func (h *ServiceHandler) InsertUserMessage(c iris.Context) {
	var req rpc.InsertMessageReq
	if err := c.ReadBody(&req); err != nil {
		c.StopWithError(iris.StatusBadRequest, err)
		return
	}
	messageId := h.Idgen.Next().Int64()
	messageContent := database.MessageContent{
		ID:       messageId,
		Type:     byte(req.Message.Type),
		Body:     req.Message.Body,
		Extra:    req.Message.Extra,
		SendTime: req.SendTime,
	}
	// 扩散写
	idxs := make([]database.MessageIndex, 2)
	idxs[0] = database.MessageIndex{
		ID:        h.Idgen.Next().Int64(),
		MessageID: messageId,
		AccountA:  req.Dest,
		AccountB:  req.Sender,
		Direction: 0,
		SendTime:  req.SendTime,
	}
	idxs[1] = database.MessageIndex{
		ID:        h.Idgen.Next().Int64(),
		MessageID: messageId,
		AccountA:  req.Sender,
		AccountB:  req.Dest,
		Direction: 1,
		SendTime:  req.SendTime,
	}

	err := h.MessageDb.Transaction(func(tx *gorm.DB) error {
		if err := tx.Create(&messageContent).Error; err != nil {
			return err
		}
		if err := tx.Create(&idxs).Error; err != nil {
			return err
		}
		return nil
	})
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
	_, _ = c.Negotiate(&rpc.InsertMessageResp{
		MessageId: messageId,
	})
}
```

#### 群聊消息存储

群聊的逻辑比单聊多了一次`群成员的查询`，然后再扩散写到索引表中。代码如下：
```go
// services/service/handler/message_handler.go

package handler

func (h *ServiceHandler) InsertGroupMessage(c iris.Context) {
	var req rpc.InsertMessageReq
	if err := c.ReadBody(&req); err != nil {
		c.StopWithError(iris.StatusBadRequest, err)
		return
	}
	messageId := h.Idgen.Next().Int64()

	var members []database.GroupMember
	err := h.BaseDb.Where(&database.GroupMember{Group: req.Dest}).Find(&members).Error
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
	// 扩散写
	var idxs = make([]database.MessageIndex, len(members))
	for i, m := range members {
		idxs[i] = database.MessageIndex{
			ID:        h.Idgen.Next().Int64(),
			MessageID: messageId,
			AccountA:  m.Account,
			AccountB:  req.Sender,
			Direction: 0,
			Group:     m.Group,
			SendTime:  req.SendTime,
		}
		if m.Account == req.Sender {
			idxs[i].Direction = 1
		}
	}

	messageContent := database.MessageContent{
		ID:       messageId,
		Type:     byte(req.Message.Type),
		Body:     req.Message.Body,
		Extra:    req.Message.Extra,
		SendTime: req.SendTime,
	}

	err = h.MessageDb.Transaction(func(tx *gorm.DB) error {
		if err := tx.Create(&messageContent).Error; err != nil {
			return err
		}
		if err := tx.Create(&idxs).Error; err != nil {
			return err
		}
		return nil
	})

	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
	_, _ = c.Negotiate(&rpc.InsertMessageResp{
		MessageId: messageId,
	})
}
```

#### 消息ACK实现

在上一章节介绍过，我们把`读索引`直接存放到Redis中，相比存储在数据库表中速度更快。逻辑如下：
```go
// services/service/handler/message_handler.go
package handler

func (h *ServiceHandler) MessageAck(c iris.Context) {
	var req rpc.AckMessageReq
	if err := c.ReadBody(&req); err != nil {
		c.StopWithError(iris.StatusBadRequest, err)
		return
	}
	// save in redis
	err := setMesssageAck(h.Cache, req.Account, req.MessageId)
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
}

func setMesssageAck(cache *redis.Client, account string, msgId int64) error {
	if msgId == 0 {
		return nil
	}
	key := database.KeyMessageAckIndex(account)
	return cache.Set(key, msgId, wire.OfflineReadIndexExpiresIn).Err()
}
```

在redis中，标准Key的格式为`key:key:key`，我们统一封装到一个地方：
```go
package database

func KeyMessageAckIndex(account string) string {
	return fmt.Sprintf("chat:ack:%s", account)
}
```

**如下是离线消息相关的全局配置常量：**

```go
const (
	OfflineReadIndexExpiresIn = time.Hour * 24 * 30 // 读索引在缓存中的过期时间
	OfflineSyncIndexCount     = 2000  //单次同步消息索引的数量
	OfflineMessageExpiresIn   = 15 // 离线消息过期时间
	MessageMaxCountPerPage    = 200 // 同步消息内容时每页的最大数据
)
```

这几个参数在下面会使用到，这里提前说明下。

> 在本小册中，我们没有实现多设备同时登录，读者可以思考下，`多设备`情况下离线消息的同步逻辑？

### 离线消息实现

同样，离线消息的两个接口如下：
```go
offlineAPI := app.Party("/api/:app/offline")
{
        offlineAPI.Use(iris.Compression)
        offlineAPI.Post("/index", serviceHandler.GetOfflineMessageIndex)
        offlineAPI.Post("/content", serviceHandler.GetOfflineMessageContent)
}
```

#### 同步消息索引

同步索引是`核心逻辑`，我们重点介绍下。首先从**抽象逻辑层面**来思考，则只有如下三步：

![GetOfflineMessageIndex.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f7d02a0a56b44a16b719e417139e3617~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

1. 获取`读索引`的全局时钟。
2. 根据这个`全局时钟`，从DB中把消息索引读取出来。
3. 重置`读索引`位置。

代码如下：
```go
// services/service/handler/message_handler.go

func (h *ServiceHandler) GetOfflineMessageIndex(c iris.Context) {
	var req rpc.GetOfflineMessageIndexReq
	if err := c.ReadBody(&req); err != nil {
		c.StopWithError(iris.StatusBadRequest, err)
		return
	}
	msgId := req.MessageId
	start, err := h.getSentTime(req.Account, req.MessageId)
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}

	var indexs []*rpc.MessageIndex
	tx := h.MessageDb.Model(&database.MessageIndex{}).Select("send_time", "account_b", "direction", "message_id", "group")
	err = tx.Where("account_a=? and send_time>? and direction=?", req.Account, start, 0).Order("send_time asc").Limit(wire.OfflineSyncIndexCount).Find(&indexes).Error
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
	err = setMesssageAck(h.Cache, req.Account, msgId)
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
	_, _ = c.Negotiate(&rpc.GetOfflineMessageIndexResp{
		List: indexs,
	})
}
```

- `setMesssageAck`这个方法在前面的消息ACK中已经给出，在这里如果msgId为0，是不会重置读索引的。

其中获取`读索引`的全局时钟就是在`getSentTime`这个方法中，在实现它之前，你需要对前面介绍的理论知识完全理解。
```go
// services/service/handler/message_handler.go

func (h *ServiceHandler) getSentTime(account string, msgId int64) (int64, error) {
	// 1. 冷启动情况，从服务端拉取消息索引
	if msgId == 0 {
		key := database.KeyMessageAckIndex(account)
		msgId, _ = h.Cache.Get(key).Int64() // 如果一次都没有发ack包，这里就是0
	}
	var start int64
	if msgId > 0 {
		// 2.根据消息ID读取此条消息的发送时间。
		var content database.MessageContent
		err := h.MessageDb.Select("send_time").First(&content, msgId).Error
		if err != nil {
			//3.如果此条消息不存在，返回最近一天。
			start = time.Now().AddDate(0, 0, -1).UnixNano()
		} else {
			start = content.SendTime
		}
	}
	// 4.返回默认的离线消息过期时间
	earliestKeepTime := time.Now().AddDate(0, 0, -1*wire.OfflineMessageExpiresIn).UnixNano()
	if start == 0 || start < earliestKeepTime {
		start = earliestKeepTime
	}
	return start, nil
}
```

- `冷启动`: 指在某个设备中第一次启动。或者在web端没有本地消息存储的情况下，第一次同步索引，消息ID就会为空。

在设计表时，我们把`SentTime`冗余存储在了消息内容表`t_message_content`中，它的作用就是根据`消息ID`读取`物理时钟`。

> 读者可以思考下，为什么不直接从t_message_index表读取？

#### 下载消息内容

下载消息内容就比如简单了，直接从数据库中读取。在这里我们限制了一次读取的消息最大数据，即200条。
```go
// services/service/handler/message_handler.go

func (h *ServiceHandler) GetOfflineMessageContent(c iris.Context) {
	var req rpc.GetOfflineMessageContentReq
	if err := c.ReadBody(&req); err != nil {
		c.StopWithError(iris.StatusBadRequest, err)
		return
	}
	mlen := len(req.MessageIds)
	if mlen > wire.MessageMaxCountPerPage {
		c.StopWithText(iris.StatusBadRequest, "too many MessageIds")
		return
	}
	var contents []*rpc.Message
	err := h.MessageDb.Model(&database.MessageContent{}).Where(req.MessageIds).Find(&contents).Error
	if err != nil {
		c.StopWithError(iris.StatusInternalServerError, err)
		return
	}
	_, _ = c.Negotiate(&rpc.GetOfflineMessageContentResp{
		List: contents,
	})
}
```

**本章完！**