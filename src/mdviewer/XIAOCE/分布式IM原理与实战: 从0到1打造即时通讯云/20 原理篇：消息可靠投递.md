在即时通讯系统中，有两个重要指标：`可靠投递`与`即时投递`。可靠投递要求系统在复杂的网络环境或者服务故障情况下也要尽量保证**消息不丢失。即时投递**则是要求发送的消息能尽快送达对方，如果对方处于离线状态，则通过`推送服务`把消息异步投递过去，不过离线的推送功能不在本小册的范围内，所以我们重点介绍消息的`可靠投递`逻辑。

![chapter20.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/099b99722d4a4afb8ac167ddfc2c5aec~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

### 理论基础

在实现消息可靠性投递之前，我们首先了解下在分布式系统中，数据同步方面的一些基本的理论及实现原理，当然这里不是介绍CAP理论。

实际上在前面**通信协议之状态**一章协议的分解图中，**传输层**的两种协议`UDP`与`TCP`，它们投递消息的`实现原理`就是我们可以借鉴的对象，比如UDP就只发送一次而不管接收方是否收到消息，而TCP则保证消息投递的可靠性，当然在这里我不准备深入介绍TCP是如何保证可靠性的，相信读者或多或少也了解过。因此我们回到做后台开发的读者比较了解的一个领域`消息中间件`，如Kafka，它定义了消息投递的几种情况：

- `最多一次`（At-most Once）
- `最少一次`（At-least Once）
- `正好一次`（Exactly Once）

> 而IM的消息投递可靠性的道理与之相同，我们来分析一下它们的含义及逻辑。

#### 最多一次

这个是最简单的实现方式，在上一章节中，如果没有其它逻辑，实际上它就是一个`At-most Once`的逻辑，也就是像UDP一样把消息发送过去就完事了。它的优点就是实现简单，缺点嘛~

- 就是会被产品经理da死。。。

#### 最少一次

最少一次即保证消息至少投递一次到接收方，也就是说接收方可能收到重复的消息。要实现这一点就需要SDK给服务端一个ACK，告诉消息已经接收到，如下图：

![At_least_Once.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e3396fb6d01c47f1883512933fe1a0f6~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

如果接收方在`第2步`完成之后发生异常断开了连接，ACK消息也就无法送达给服务端，**因此服务端会认为接收方没有收到这条消息**，当接收方再次重连登录之后，就会把这条消息发送过去。可以看到，在这种情况下，**接收方业务层就会接收到重复的消息**。

> 是不是与TCP中的消息`AC`K和`重传`相似！

#### 正好一次

从分布式系统的理论上来说，Exactly-once投递是不可能的，它的代价太高无法实际应用到生产环境，也就是说无法达到上图中的`第1步`和`第2步`**同时只执行一次**。但是我们可以通过SDK的`幂等`处理，对上层业务来说达到同样的效果。

> **幂等**（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中一个**幂等**操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。

![exactly_once.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/40c514be27cd452cb106299a4be4c52b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

在SDK端，我们把消息通过数据库的`主键唯一的特性`，也能达到**幂等**的效果。还是上面的逻辑，当第一次收到消息之后，SDK就会把它写入本地数据库，成功之后就上报给业务层；如果**相同ID**的消息第二次发送到SDK端，此时再插入数据就会主键冲突报错，也就无需通知给上层业务了，因此对业务层来说服务端消息的投递就是**Exactly-once**。

> 搞明白了以上原理，我们正式进入主题！

### 可靠投递

消息的`可靠投递`是IM系统的核心基础，也是一个难点。读者需要注意的是与**消息中间件MQ**的差异，虽然同样有消息的生产与消费，看似相同，但是在消息中间件中通常消息的**生产与消费是异步的**。如下是一个大致的示意图：

![mq_flow.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/398537faad7a4549af3d659c34bb04af~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

如果消费者一直不消费，那么队列中的读位置与队列尾部的偏移量会非常大；当消费者进程启动之后，如果它不想丢掉消息，只能慢慢的依次消费，当然通常情况下使用消息中间件的业务场景也不要求很高的即时性。但是在IM中确强调消息的`即时性`，IM中的在线消息是立即`Push`给接收方。如果接收方不在线，当它再次上线时，则要在非常短的时间内同步完**离线消息**。

> 因此在聊天场景中，单一用户的离线消息的要么`有数量限制`，要么离线消息会有一个`存活时间`，超出范围的消息将被丢弃。

回到本小册的IM实战项目中，我们也是基于`正好一次`（Exactly Once）来设计消息的投递逻辑，**但是这需要SDK的配合**。我为什么强调**需要SDK的配合**这一点呢，因为在本小册的web端SDK实战中没有准备开发本地存储逻辑。即使有，用户更换一个浏览器也就相当于没有了，而且更换浏览器的的代价相对于App端来说太小，我们无法要求用户总是使用同一个浏览器或者不清理缓存。当然了，在web端支持这个功能也可以很大概率减少出现重复的未读消息的概率。

> 接下来，我们看看在IM系统中，在线与离线状态下消息的投递逻辑。

#### 在线逻辑

##### 接收端

在前一章节，发送方投递的消息到达Chat服务之后，**首先就是写入离线队列，而不管接收方是否在线**。假如服务端认为接收方“在线”就不存储消息，一种可能的情况就是接收方处于异常离线但服务端还未检测到的状态，此时消息是无法送达到接收方的；或者说接**收方收到的消息之后`crash`了**，这些情况都会导致消息**投递失败**。

因此，通常消息的投递成功一定是基于接收方主动确认告知服务端，如下图：

![user_talk_offline_diagram1.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7abdd9b20c354f619d4d7675856151ea~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

从消息的发送到消息的成功投递一共有四步：

- `发送方`把消息投递到服务端，并存储到`接收方`的离线队列。
- 消息被投递给`接收方`，SDK把消息写入本地数据库（如sqlite）。
- `接收方`回复一条ACK消息给服务端，服务端把消息设置为已读。

如果接收方没有回复ACK，那么这条消息就成了离线消息，在接收方重连登陆之后，离线同步逻辑会把消息同步到SDK端。

> 我们接着分析这个逻辑，还有优化的空间吗？

在聊天场景下，通常消息的收发是连续性的，在一断时间用户非常活跃，如果每收到一条消息就回复一条ACK，在一定程度是有点浪费服务端资源，因此SDK端收到消息之后可以间隔一段时间之后，一次性回复一条ACK消息。如下图所示：

![user_talk_offline_diagram2.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/64afe1fd28cd4bf2808d2103a6899d50~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

在上图中，用户B的SDK端收到消息a、b之后没有立刻回复ACK消息，而是在delay一段时间之后，通过一个ACK的批量操作，告诉服务端`a、b、c、d`四条消息已经接收完成，如果此时用户B断线重连进入系统，这四条消息是`不会当作离线消息`同步过来的。

##### 发送端

在上一章节，相信一些细心的读者已经看出来，`消息的发送成功的标志`就是消息持久化到了服务端数据库中。**而无需关心这条消息是否投递到了接收方**，这在一定程序上是对逻辑的解耦，既可以保证消息的可靠性，也大大简化了流程，越是简单的逻辑稳定性就越高。

![send_message_confirm.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e47875a83ae94c3c887fd99d951b9d14~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

如果SDK在一段时间内没有收到服务端的Resp消息，或者收到的Resp中返回的status状态不是Success，SDK就需要做出对应的反应，主要有如下三种：

- `消息重发`
- `断线重连`
- `错误上报给业务层`

而这个判断的依据则是根据返回的`status`与`定义的规则`来决定的，我们在介绍SDK逻辑时再详细介绍。

#### 离线逻辑

介绍完了在线状态的消息处理过程，接下来一起来了解下离线逻辑。当一个用户离线之后，再次登陆到服务端时，就需要同步离线消息，也就是把下线的时间段内其它人发送过来的消息同步下来。而同步的方式有推（Push）和拉（Pull）两种。

- 推（Push）：指用户登陆之后，服务端主动把离线消息Push过去。
- 拉（Pull）：指用户登陆之后，通过接口或者长连指令主动拉离线消息。

Push与Pull的区别在于谁主动发起。在离线消息逻辑中，为了尽快同步完所有离线消息，消息被批量打成一个包发送给接收方，不会像在线推送一样一条一条。如下图：

![offline_pull_push.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed8faa7ef2a245d294ceb65f33733875~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

上图中的`结束条件`指SDK端确认消息已经同步完，`但是只要有一条消息返回，最后一次的ACK就不能少`。可以看到除了出发点不同，它们之后的逻辑就比较相同的，但是它们各有优缺点：

- Push方式对SDK端的逻辑更简单，但是它不太灵活，开始之后SDK就无法停止，直到消息全部同步完。比如在非常活跃的群特别多的App场景下，用户离线一周之后可能会有1w+的离线消息生产，**假设每次我们推送100条消息，就要推送100次，如果加上每个轮回中SDK存储本地数据库所占的时间**，就会导致APP一直阻塞在登录状态中。
- Pull方式对SDK来说复杂一点，但是它更灵活。比如**Pull的方式不一定走Chat通信服务，也可以走Http接口服务**。

> **在本实战项目KIM中**，我们采用`Pull`拉的方式处理离线逻辑。

### 逻辑优化

#### 请求合并

首先，在上面的Pull流程中，每个轮次的**消息同步**都有两次请求Request和Ack，因此我们考虑把它们合并为一次请求。如下图：

![offline_pull_optimized_1.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/573de9977721439aa12a32c53001d38d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

在上面的流程中，我们在请求离线消息时，会把`上一轮`要**确认的消息ID**一并带过去。比如请求包参数如下：

> Requet offline message:

|属性|	类型|	描述|
| - | - | - |
|account|	string|	接收方账号|
|ack_message_ids|	[]int64|	待确认的消息ID|

`第一次请求时，可以把ack_message_ids传空`，只当是一次GET操作。

#### ACK消息ID合并

在上面的逻辑中，我们存储的离线消息是基于**状态位**来表示的，我们以mysql表为例来说明这个问题，假设如下就是离线消息表，我们设置一个`delivered`字段来表示**消息是否已确认被投递到了接收方**：

|message_id|	`receiver`|	sender|	type|	body|	delivered|
| - | - | - | - | - | - |
|11111|	user_b|	user_a|	text|	a|	1|
|11112|	user_b|	user_a|	text|	b|	0|
|11113|	user_b|	user_a|	text|	c|	0|
|11114|	user_b|	user_a|	text|	d|	0|

如上是user_a给user_b发送的四条消息，其中消息**b、c和d**就是离线消息，还未被ACK确认。因此下次`同步离线消息时，必须更新消息ID为11112、11113和11114这三条消息`，而数据库的更新操作也是一个较`耗时`的IO操作，这对一个高频的消息收发IM系统的性能影响是非常大的。

因此我们通过给每个用户在服务端添加一个`读索引`，而同时与SDK约定一条规则，`即在ACK时，只需要给一条发送时间最大的消息ID即可`。这个逻辑同样适用于`在线状态`的ACK，这个逻辑是基于我们假设**用户确认收到了一条消息，那么这条消息之前的所有消息就一定收到了**！ 虽然在分布式系统中很难保证消息的绝对顺序。

![user_talk_offline_diagram3.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/19352d77e8464a92b4002afdfe82cb4f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

因此，我们删除上表中的`delivered`字段，而使用下面的索引`latest_ack_msg_id`代替。这样每次消息Ack时无论有多少条消息，**只需要更新一条记录即可**。在本KIM项目中，为了近一步提高它的更新速度，我们把这个索引保存在了缓存Redis中。如下是一个读索引的示意结构：

|receiver|	`latest_ack_msg_id`|
| - | - |
|user_b|	11112|

使用读索引的另一个好处就是SDK登录之后，第一次请求离线消息时，可以把**本地数据库**中`最后一条消息的ID`作为`latest_ack_msg_id`的值，这样可以近一步解决本地SDK的读索引与服务端读索引不一致导致的消息重复同步。比如本地的最大读消息索引为`18`，因为SDK**最后一批消息**还没有ACK给服务端就离线了，此时服务端的读了索引为`10`，那么第一次同步消息时，就可以`减少8条消息`的同步。

#### 索引与内容分离

由于我们设计的是Paas即时通讯云服务，因此在考虑时，就不能把微信这种用户粘性非常强的App当作示例来设计离线消息逻辑。

实际情况可能是，用户离线几天之后，打开App登录时，会有1w+（大群较多）以上的消息需要同步，这会导致程序阻塞在消息同步过程中；而且不同步离线也不行，除非逻辑上设置一个`很小的离线消息上限`，比如1k。否则，如果一部分离线消息没有同步，`读索引`跳过了它们，之后就不会把它们当成离线消息同步了。

在本实战项目`KIM`中，我们解决这个问题的办法就是把`消息的索引`与`消息的内容`分开。因为索引的体积非常小，而且体积非常稳定的，**不像消息内容的大小受用户输入的影响**，因此可以在一次请求中`返回大量索引`，同步完索引之后，登录就完成了。在客户端，当用户点击会话列表，进入某个单聊或者群聊的会话中时，就可以根据**已经下载的索引**动态加载消息内容。如下图简单的流程图：

![load_offline_index_flow.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7a6441faaa424c41b10d8d6d67f73217~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

可以看到，一个消息被分为两部分，分别在两个不同的逻辑中处理。

- 消息索引

|message_id|	receiver|	sender|	sendTime|
| - | - | - | - |
|11111|	user_b|	user_a|	1232354345|
|11112|	user_b|	user_a|	1234234345|

- 消息内容

|message_id|	type|	body|	extra|
| - | - | - | - |
|11111|	text|	hello	| |
|11112|	text|	world	| |

> `以上的所有的表结构只是为了说明逻辑，不代表最终结果。`

### 最后总结

本章我们从分布式系统中的数据同步的理论开始，详细解决了在IM中消息投递过程中在线与离线的核心逻辑。在下一章节，我们将详细介绍消息的存储逻辑，即`读扩散`or`写扩散`情况下的如何设计存储；并且实现`消息存储`、`消息ACK`与`离线消息同步`等逻辑。

**本章完！**